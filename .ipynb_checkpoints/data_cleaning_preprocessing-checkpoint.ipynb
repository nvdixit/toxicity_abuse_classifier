{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the cyberbullying raw data\n",
    "df_cyberbullying = pd.read_csv('./Raw Data/cyberbullying_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the toxic tweets raw data\n",
    "df_abuse = pd.read_csv('./Raw Data/Toxic_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the labels of each datapoint to match each other\n",
    "df_cyberbullying['label'] = df_cyberbullying['label'].replace(-1, 'toxic')\n",
    "df_cyberbullying['label'] = df_cyberbullying['label'].replace(0, 'not_toxic')\n",
    "\n",
    "df_abuse['Toxicity'] = df_abuse['Toxicity'].replace(0, 'not_toxic')\n",
    "df_abuse['Toxicity'] = df_abuse['Toxicity'].replace(1, 'toxic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the extra column in abuse_df\n",
    "df_abuse.drop(columns=['Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swap the columns of df_abuse\n",
    "df_abuse = df_abuse[['tweet', 'Toxicity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns of both dataframes\n",
    "df_abuse = df_abuse.rename(columns={'tweet': 'comment', 'Toxicity': 'label'})\n",
    "df_cyberbullying = df_cyberbullying.rename(columns={'headline': 'comment', 'label': 'label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove some non-English entries in the dataset\n",
    "df_cyberbullying = df_cyberbullying.drop(df_cyberbullying.index[15307:18148])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the 2 dataframes into 1\n",
    "df = pd.concat([df_abuse, df_cyberbullying])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the dataframe's index column\n",
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the extra index column in the dataframe\n",
    "df.drop(columns=['index'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikhildixit/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \n",
      "/Users/nikhildixit/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/nikhildixit/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \n",
      "/Users/nikhildixit/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  import sys\n",
      "/Users/nikhildixit/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "# Remove all twitter handles and hashtags from the dataset\n",
    "df['comment'] = df['comment'].str.replace(r'@([A-Za-z0-9_]+)', '')\n",
    "df['comment'] = df['comment'].str.replace(r'#([A-Za-z0-9_]+)', '')\n",
    "\n",
    "# Remove all punctuation from dataset\n",
    "df['comment'] = df['comment'].str.replace(r'[^\\w\\s]+', '')\n",
    "df['comment'] = df['comment'].str.replace(r'\\d+', '')\n",
    "\n",
    "# Lowercase all comments\n",
    "df['comment'] = df['comment'].str.lower()\n",
    "\n",
    "# Remove all non-ASCII characters in the dataset\n",
    "df['comment'] = df['comment'].str.replace(r'[^\\x00-\\x7F]+', '')\n",
    "\n",
    "# Trim excess whitespace around each entry\n",
    "df['comment'] = df['comment'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/nikhildixit/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Lemmatize the corpus and remove stopwords\n",
    "nltk.download('wordnet');\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    lemmatized = []\n",
    "    for w in text.split(' '):\n",
    "        if w not in stop_words and len(w) > 0:\n",
    "            lemmatized.append(lemmatizer.lemmatize(w))\n",
    "    \n",
    "    cleaned_text = ' '.join(lemmatized)\n",
    "    return cleaned_text\n",
    "\n",
    "df['comment'] = df['comment'].apply(lemmatize_text)\n",
    "df['comment'] = df['comment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all blank comments with NaN\n",
    "df = df.replace(r'^s*$', float('NaN'), regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all NaN values\n",
    "df.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly shuffle the dataframe\n",
    "df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>went sister makeup cant find sample lipstick got looking forward using</td>\n",
       "      <td>not_toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>car selfie</td>\n",
       "      <td>not_toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im finally get get</td>\n",
       "      <td>not_toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rt k michelle apart baltimore twitter shed one hoe saying shes celibate smh</td>\n",
       "      <td>toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rt really get excited see bad bitch association lunch everyday always make laugh</td>\n",
       "      <td>toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71584</th>\n",
       "      <td>he lying faggot used inspect element change number dollar account</td>\n",
       "      <td>toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71585</th>\n",
       "      <td>redirect talk g u district</td>\n",
       "      <td>not_toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71586</th>\n",
       "      <td>victim adam saleh refers black people abeed slave one sketch</td>\n",
       "      <td>toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71587</th>\n",
       "      <td>ive year mostly amp even leave die</td>\n",
       "      <td>toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71588</th>\n",
       "      <td>cause said dident shit u</td>\n",
       "      <td>toxic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71589 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                comment  \\\n",
       "0                went sister makeup cant find sample lipstick got looking forward using   \n",
       "1                                                                            car selfie   \n",
       "2                                                                    im finally get get   \n",
       "3           rt k michelle apart baltimore twitter shed one hoe saying shes celibate smh   \n",
       "4      rt really get excited see bad bitch association lunch everyday always make laugh   \n",
       "...                                                                                 ...   \n",
       "71584                 he lying faggot used inspect element change number dollar account   \n",
       "71585                                                        redirect talk g u district   \n",
       "71586                      victim adam saleh refers black people abeed slave one sketch   \n",
       "71587                                                ive year mostly amp even leave die   \n",
       "71588                                                          cause said dident shit u   \n",
       "\n",
       "           label  \n",
       "0      not_toxic  \n",
       "1      not_toxic  \n",
       "2      not_toxic  \n",
       "3          toxic  \n",
       "4          toxic  \n",
       "...          ...  \n",
       "71584      toxic  \n",
       "71585  not_toxic  \n",
       "71586      toxic  \n",
       "71587      toxic  \n",
       "71588      toxic  \n",
       "\n",
       "[71589 rows x 2 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./Clean Data/clean_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
