{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the cyberbullying raw data\n",
    "df_cyberbullying = pd.read_csv('../Raw Data/cyberbullying_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the toxic tweets raw data\n",
    "df_abuse = pd.read_csv('../Raw Data/Toxic_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the labels of each datapoint to match each other\n",
    "df_cyberbullying['label'] = df_cyberbullying['label'].replace(-1, 'toxic')\n",
    "df_cyberbullying['label'] = df_cyberbullying['label'].replace(0, 'not_toxic')\n",
    "\n",
    "df_abuse['Toxicity'] = df_abuse['Toxicity'].replace(0, 'not_toxic')\n",
    "df_abuse['Toxicity'] = df_abuse['Toxicity'].replace(1, 'toxic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the extra column in abuse_df\n",
    "df_abuse.drop(columns=['Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swap the columns of df_abuse\n",
    "df_abuse = df_abuse[['tweet', 'Toxicity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns of both dataframes\n",
    "df_abuse = df_abuse.rename(columns={'tweet': 'comment', 'Toxicity': 'label'})\n",
    "df_cyberbullying = df_cyberbullying.rename(columns={'headline': 'comment', 'label': 'label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove some non-English entries in the dataset\n",
    "df_cyberbullying = df_cyberbullying.drop(df_cyberbullying.index[15307:18148])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the 2 dataframes into 1\n",
    "df = pd.concat([df_abuse, df_cyberbullying])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the dataframe's index column\n",
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the extra index column in the dataframe\n",
    "df.drop(columns=['index'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikhildixit/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \n",
      "/Users/nikhildixit/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/nikhildixit/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \n",
      "/Users/nikhildixit/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  import sys\n",
      "/Users/nikhildixit/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "# Remove all twitter handles and hashtags from the dataset\n",
    "df['comment'] = df['comment'].str.replace(r'@([A-Za-z0-9_]+)', '')\n",
    "df['comment'] = df['comment'].str.replace(r'#([A-Za-z0-9_]+)', '')\n",
    "\n",
    "# Remove all punctuation from dataset\n",
    "df['comment'] = df['comment'].str.replace(r'[^\\w\\s]+', '')\n",
    "df['comment'] = df['comment'].str.replace(r'\\d+', '')\n",
    "\n",
    "# Lowercase all comments\n",
    "df['comment'] = df['comment'].str.lower()\n",
    "\n",
    "# Remove all non-ASCII characters in the dataset\n",
    "df['comment'] = df['comment'].str.replace(r'[^\\x00-\\x7F]+', '')\n",
    "\n",
    "# Trim excess whitespace around each entry\n",
    "df['comment'] = df['comment'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/nikhildixit/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Lemmatize the corpus and remove stopwords\n",
    "nltk.download('wordnet');\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    lemmatized = []\n",
    "    for w in text.split(' '):\n",
    "        if w not in stop_words and len(w) > 0:\n",
    "            lemmatized.append(lemmatizer.lemmatize(w))\n",
    "    \n",
    "    cleaned_text = ' '.join(lemmatized)\n",
    "    return cleaned_text\n",
    "\n",
    "df['comment'] = df['comment'].apply(lemmatize_text)\n",
    "df['comment'] = df['comment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all blank comments with NaN\n",
    "df = df.replace(r'^s*$', float('NaN'), regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all NaN values\n",
    "df.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly shuffle the dataframe\n",
    "df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep the first 30,000 data points\n",
    "df = df.head(30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>life make let make</td>\n",
       "      <td>not_toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pete make think go around spread insult personal attack make think call arrogant rude kick would report ongoing behavior block maybe someone see page recruiting editor irrelevant read post mine yahoo see told everyone regardless position appreciate presence trying convince people come post pov mind fact someone come post pov completely beyond control finally discus edits discussed talk page week four editor edit make original proposal deleting entire section however preserved critical point paragraph moved reception steiner get rid problem undue weight</td>\n",
       "      <td>not_toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hot chocolate famous amos bomb right</td>\n",
       "      <td>not_toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>homo sex ity french fried faggot going cut ball serve platter mushroom shoving dick as mutilating boyfriend ball front kill</td>\n",
       "      <td>toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>whew productive</td>\n",
       "      <td>not_toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>rt much wife wet pussy want another dick head</td>\n",
       "      <td>toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>let say plain simple two</td>\n",
       "      <td>not_toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>orr thts lor bae tho wyd u fucking hoe</td>\n",
       "      <td>toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>hoe</td>\n",
       "      <td>toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>posted ig going bed early</td>\n",
       "      <td>not_toxic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              comment  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  life make let make   \n",
       "1      pete make think go around spread insult personal attack make think call arrogant rude kick would report ongoing behavior block maybe someone see page recruiting editor irrelevant read post mine yahoo see told everyone regardless position appreciate presence trying convince people come post pov mind fact someone come post pov completely beyond control finally discus edits discussed talk page week four editor edit make original proposal deleting entire section however preserved critical point paragraph moved reception steiner get rid problem undue weight   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                hot chocolate famous amos bomb right   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                         homo sex ity french fried faggot going cut ball serve platter mushroom shoving dick as mutilating boyfriend ball front kill   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     whew productive   \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               ...   \n",
       "29995                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   rt much wife wet pussy want another dick head   \n",
       "29996                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        let say plain simple two   \n",
       "29997                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          orr thts lor bae tho wyd u fucking hoe   \n",
       "29998                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             hoe   \n",
       "29999                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       posted ig going bed early   \n",
       "\n",
       "           label  \n",
       "0      not_toxic  \n",
       "1      not_toxic  \n",
       "2      not_toxic  \n",
       "3          toxic  \n",
       "4      not_toxic  \n",
       "...          ...  \n",
       "29995      toxic  \n",
       "29996  not_toxic  \n",
       "29997      toxic  \n",
       "29998      toxic  \n",
       "29999  not_toxic  \n",
       "\n",
       "[30000 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../Clean Data/clean_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
