{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set pandas to display the whole dataframe\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the cyberbullying raw data\n",
    "df_cyberbullying = pd.read_csv('../Raw Data/cyberbullying_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the toxic tweets raw data\n",
    "df_abuse = pd.read_csv('../Raw Data/Toxic_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the labels of each datapoint to match each other\n",
    "df_cyberbullying['label'] = df_cyberbullying['label'].replace(-1, 'toxic')\n",
    "df_cyberbullying['label'] = df_cyberbullying['label'].replace(0, 'not_toxic')\n",
    "\n",
    "df_abuse['Toxicity'] = df_abuse['Toxicity'].replace(0, 'not_toxic')\n",
    "df_abuse['Toxicity'] = df_abuse['Toxicity'].replace(1, 'toxic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the extra column in abuse_df\n",
    "df_abuse.drop(columns=['Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swap the columns of df_abuse\n",
    "df_abuse = df_abuse[['tweet', 'Toxicity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns of both dataframes\n",
    "df_abuse = df_abuse.rename(columns={'tweet': 'comment', 'Toxicity': 'label'})\n",
    "df_cyberbullying = df_cyberbullying.rename(columns={'headline': 'comment', 'label': 'label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove some non-English entries in the dataset\n",
    "df_cyberbullying = df_cyberbullying.drop(df_cyberbullying.index[15307:18148])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly shuffle both dataframes\n",
    "df_abuse = df_abuse.sample(frac=1).reset_index(drop=True)\n",
    "df_cyberbullying = df_cyberbullying.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep the first 15000 entries of df_abuse (dataset is too large otherwise)\n",
    "df_abuse = df_abuse.head(15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the 2 dataframes into 1\n",
    "df = pd.concat([df_abuse, df_cyberbullying])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly shuffle the dataframe\n",
    "df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikhildixit/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \n",
      "/Users/nikhildixit/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/nikhildixit/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \n",
      "/Users/nikhildixit/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  import sys\n",
      "/Users/nikhildixit/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "# Remove all twitter handles and hashtags from the dataset\n",
    "df['comment'] = df['comment'].str.replace(r'@([A-Za-z0-9_]+)', '')\n",
    "df['comment'] = df['comment'].str.replace(r'#([A-Za-z0-9_]+)', '')\n",
    "\n",
    "# Remove all punctuation from dataset\n",
    "df['comment'] = df['comment'].str.replace(r'[^\\w\\s]+', '')\n",
    "df['comment'] = df['comment'].str.replace(r'\\d+', '')\n",
    "\n",
    "# Lowercase all comments\n",
    "df['comment'] = df['comment'].str.lower()\n",
    "\n",
    "# Remove all non-ASCII characters in the dataset\n",
    "df['comment'] = df['comment'].str.replace(r'[^\\x00-\\x7F]+', '')\n",
    "\n",
    "# Trim excess whitespace around each entry\n",
    "df['comment'] = df['comment'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/nikhildixit/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Lemmatize the corpus and remove stopwords\n",
    "nltk.download('wordnet');\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    lemmatized = []\n",
    "    for w in text.split(' '):\n",
    "        if w not in stop_words and len(w) > 0:\n",
    "            lemmatized.append(lemmatizer.lemmatize(w))\n",
    "    \n",
    "    cleaned_text = ' '.join(lemmatized)\n",
    "    return cleaned_text\n",
    "\n",
    "df['comment'] = df['comment'].apply(lemmatize_text)\n",
    "df['comment'] = df['comment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all blank comments with NaN\n",
    "df = df.replace(r'^s*$', float('NaN'), regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all NaN values\n",
    "df.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the dataframe's index column\n",
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the extra index column in the dataframe\n",
    "df.drop(columns=['index'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dude dude stop busting ball</td>\n",
       "      <td>toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>offended birther analogy consider analogy including title like dark moon apollo whistle blower bill kaysing see also section neil armstrong buzz aldrin fortunately book article yet stand amazon best seller list compared montford obviously moon landing hoax conspiracy theory quite bit obvious piece fringe nonsense yet sale figure would indicate taken seriously many except nasa partisan namely almost everybody</td>\n",
       "      <td>not_toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>merge suggested article branding iron merged one</td>\n",
       "      <td>not_toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>haha fuck edit page midarme cant mdiarme cant cause bitch wait</td>\n",
       "      <td>toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>intended go page</td>\n",
       "      <td>not_toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30183</th>\n",
       "      <td>pansy multiple source reporting shot french warplane stop censoring wikipedia as hole claim libya manipulating report concidering coalition also taking account manipulating report cencoring information suck agsman</td>\n",
       "      <td>toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30184</th>\n",
       "      <td>sunday mood allanxreyes</td>\n",
       "      <td>not_toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30185</th>\n",
       "      <td>panel antitrump pundit felt like obviously pathetic attempt sway undecided voter suppoing trump</td>\n",
       "      <td>not_toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30186</th>\n",
       "      <td>bitch stop spreading mongol propaganda anything make bulgars look like bad guy must remove order spread propaganda like macedonian forum may add end getting owned would like take look ethnic map yugoslavia created nazi macedonian included seperate ethnic group right bulgaren mazedonier let closer look shall full cleaned nob article removed irrelevant information like stupid shit imro involvement talked war word count included bulgaria time macedonia entire article said take mongol propaganda shove as nazi</td>\n",
       "      <td>toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30187</th>\n",
       "      <td>marduk abraham early prophet line reflected history world marduk regional variant abraham zoroaster adam know first prophet dyeus first human consciousness see history dyeus became zeus jupiter piter fertilitycult distortion yah etc god ofcourse many idris second prophet tengri became thor many place sometimes god sometimes prophet indra prometheus osiris concept known everywhere local variation knowing regional name one see change region talk marduk change early prophetic teaching abraham sarai bible saraswati hinduism sarpanit obviously prophetic line teaching monotheism god without others peace</td>\n",
       "      <td>not_toxic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30188 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            comment  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       dude dude stop busting ball   \n",
       "1                                                                                                                                                                                                       offended birther analogy consider analogy including title like dark moon apollo whistle blower bill kaysing see also section neil armstrong buzz aldrin fortunately book article yet stand amazon best seller list compared montford obviously moon landing hoax conspiracy theory quite bit obvious piece fringe nonsense yet sale figure would indicate taken seriously many except nasa partisan namely almost everybody   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  merge suggested article branding iron merged one   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    haha fuck edit page midarme cant mdiarme cant cause bitch wait   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  intended go page   \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             ...   \n",
       "30183                                                                                                                                                                                                                                                                                                                                                                                                         pansy multiple source reporting shot french warplane stop censoring wikipedia as hole claim libya manipulating report concidering coalition also taking account manipulating report cencoring information suck agsman   \n",
       "30184                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       sunday mood allanxreyes   \n",
       "30185                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               panel antitrump pundit felt like obviously pathetic attempt sway undecided voter suppoing trump   \n",
       "30186                                                                                                bitch stop spreading mongol propaganda anything make bulgars look like bad guy must remove order spread propaganda like macedonian forum may add end getting owned would like take look ethnic map yugoslavia created nazi macedonian included seperate ethnic group right bulgaren mazedonier let closer look shall full cleaned nob article removed irrelevant information like stupid shit imro involvement talked war word count included bulgaria time macedonia entire article said take mongol propaganda shove as nazi   \n",
       "30187  marduk abraham early prophet line reflected history world marduk regional variant abraham zoroaster adam know first prophet dyeus first human consciousness see history dyeus became zeus jupiter piter fertilitycult distortion yah etc god ofcourse many idris second prophet tengri became thor many place sometimes god sometimes prophet indra prometheus osiris concept known everywhere local variation knowing regional name one see change region talk marduk change early prophetic teaching abraham sarai bible saraswati hinduism sarpanit obviously prophetic line teaching monotheism god without others peace   \n",
       "\n",
       "           label  \n",
       "0          toxic  \n",
       "1      not_toxic  \n",
       "2      not_toxic  \n",
       "3          toxic  \n",
       "4      not_toxic  \n",
       "...          ...  \n",
       "30183      toxic  \n",
       "30184  not_toxic  \n",
       "30185  not_toxic  \n",
       "30186      toxic  \n",
       "30187  not_toxic  \n",
       "\n",
       "[30188 rows x 2 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../Clean Data/clean_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
